# Approximate Booth Encoding Factored Systolic Array Design for Accelerating Neural Networks

Hardware Convolutional Neural Network (CNN) accelerators are expected to be energy-efficient and concede minimal die footprint. Systolic Array Architecture which consists of group of processing elements that are reused in the datapath flow, satisfies the above demands of hardware accelerator design. In this work, we present Systolic Array architecture which integrates radix-4 based Booth multipliers configured with approximate partial products deduced from the encoding schemes for each of the PEs in the SA. The proposed architecture supports arithmetic approximations across the SA, allowing designers to explore trade-offs between hardware characteristics, and computational accuracy. A meta-heuristic approach, based on NSGA-II algorithm allows to explore the large design space of 256 partial product combinations per PE to evolve the pareto-optimal SA configuration, that balances hardware efficiency with inference accuracy of few widely accepted neural network models. The post-synthesis results using Genus (Cadence) tool with 45 nm gpdk technology libraries for the proposed approximate booth encoding factored SA designs demonstrated 6% footprint savings on silicon, 1-2% power benefits over the state-of-the-art (SOTA) designs, while preserving model accuracy. These results highlight the effectiveness of fine grained architectural level approximation in achieving efficient CNN acceleration without compromising on the output quality. All the design files are made freely available for easy adoption and further usage to the researchers and designers community.
